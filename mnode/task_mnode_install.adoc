---
sidebar: sidebar 
permalink: mnode/task_mnode_install.html 
summary: Você pode instalar o nó de gerenciamento para o seu cluster que executa o software NetApp Element . 
keywords: netapp, element, management node, mnode, storage, install 
---
= Instale um nó de gerenciamento
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Você pode instalar manualmente o nó de gerenciamento para o seu cluster que executa o software NetApp Element usando a imagem apropriada para sua configuração.

Este processo manual destina-se a administradores de armazenamento all-flash SolidFire que não utilizam o NetApp Deployment Engine para a instalação do nó de gerenciamento.

.Antes de começar
* A versão do seu cluster está executando o software NetApp Element 11.3 ou posterior.
* Sua instalação utiliza IPv4.  O nó de gerenciamento 11.3 não suporta IPv6.
+

NOTE: Se você precisar de suporte para IPv6, pode usar o nó de gerenciamento 11.1.

* Você tem permissão para baixar software do site de suporte da NetApp .
* Você identificou o tipo de imagem do nó de gerenciamento correto para sua plataforma:
+
[cols="30,30"]
|===
| Plataforma | Tipo de imagem de instalação 


| Microsoft Hyper-V | .iso 


| KVM | .iso 


| VMware vSphere | .iso, .ova 


| Citrix XenServer | .iso 


| OpenStack | .iso 
|===
* (Nó de gerenciamento 12.0 e posterior com servidor proxy) Você atualizou o NetApp Hybrid Cloud Control para a versão 2.16 dos serviços de gerenciamento antes de configurar um servidor proxy.


.Sobre esta tarefa
O nó de gerenciamento Element 12.2 é uma atualização opcional.  Não é necessário para implantações existentes.

Antes de seguir este procedimento, você deve compreender o seguinte:link:../concepts/concept_solidfire_concepts_volumes.html#persistent-volumes["Volumes persistentes"] e se você deseja ou não usá-los.  Os volumes persistentes são opcionais, mas recomendados para a recuperação de dados de configuração do nó de gerenciamento em caso de perda de uma máquina virtual (VM).



== Passo 1: Baixe a ISO ou OVA e implante a VM.

Faça o download da ISO ou OVA apropriada no site de suporte da NetApp e instale a máquina virtual.

.Passos
. Faça o download do arquivo OVA ou ISO para sua instalação a partir dolink:https://mysupport.netapp.com/site/products/all/details/element-software/downloads-tab["Elemento Software"^] página no site de suporte da NetApp .
+
.. Selecione *Baixar a versão mais recente* e aceite o EULA.
.. Selecione a imagem do nó de gerenciamento que deseja baixar.


. Se você baixou o OVA, siga estes passos:
+
.. Implante o OVA.
.. Se o seu cluster de armazenamento estiver em uma sub-rede separada do seu nó de gerenciamento (eth0) e você quiser usar volumes persistentes, adicione uma segunda placa de rede (NIC) à máquina virtual na sub-rede de armazenamento (por exemplo, eth1) ou certifique-se de que a rede de gerenciamento possa rotear para a rede de armazenamento.


. Se você baixou a imagem ISO, siga estes passos:
+
.. Crie uma nova máquina virtual de 64 bits a partir do seu hipervisor com a seguinte configuração:
+
*** Seis CPUs virtuais
*** 24 GB de RAM
*** Tipo de adaptador de armazenamento definido como LSI Logic Paralelo
+

IMPORTANT: O padrão para seu nó de gerenciamento pode ser LSI Logic SAS.  Na janela *Nova Máquina Virtual*, verifique a configuração do adaptador de armazenamento selecionando *Personalizar hardware* > *Hardware Virtual*.  Se necessário, altere LSI Logic SAS para *LSI Logic Parallel*.

*** Disco virtual de 400 GB, com provisionamento dinâmico.
*** Uma interface de rede virtual com acesso à internet e acesso ao MVIP de armazenamento.
*** (Opcional) Uma interface de rede virtual com acesso à rede de gerenciamento do cluster de armazenamento.  Se o seu cluster de armazenamento estiver em uma sub-rede separada do seu nó de gerenciamento (eth0) e você quiser usar volumes persistentes, adicione uma segunda placa de rede (NIC) à máquina virtual na sub-rede de armazenamento (eth1) ou certifique-se de que a rede de gerenciamento possa rotear para a rede de armazenamento.
+

IMPORTANT: Não ligue a máquina virtual antes da etapa que indica que isso deve ser feito posteriormente neste procedimento.



.. Anexe a imagem ISO à máquina virtual e inicialize a partir da imagem de instalação .iso.
+

NOTE: A instalação de um nó de gerenciamento usando a imagem pode resultar em um atraso de 30 segundos antes que a tela inicial apareça.



. Ligue a máquina virtual do nó de gerenciamento após a conclusão da instalação.




== Etapa 2: Crie o administrador do nó de gerenciamento e configure a rede.

Após a conclusão da instalação da máquina virtual, crie o usuário administrador do nó de gerenciamento e configure a rede do nó de gerenciamento.

.Passos
. Utilizando a interface de usuário do terminal (TUI), crie um usuário administrador do nó de gerenciamento.
+

TIP: Para navegar pelas opções do menu, pressione as teclas de seta para cima ou para baixo.  Para navegar entre os botões, pressione Tab.  Para alternar entre os botões e os campos, pressione a tecla Tab.  Para navegar entre os campos, pressione as teclas de seta para cima ou para baixo.

. Se houver um servidor DHCP (Dynamic Host Configuration Protocol) na rede que atribua endereços IP com uma unidade máxima de transmissão (MTU) inferior a 1500 bytes, você deverá executar os seguintes passos:
+
.. Coloque temporariamente o nó de gerenciamento em uma rede vSphere sem DHCP, como iSCSI.
.. Reinicie a máquina virtual ou reinicie a rede da máquina virtual.
.. Utilizando a interface de usuário de terminal (TUI), configure o endereço IP correto na rede de gerenciamento com um MTU maior ou igual a 1500 bytes.
.. Reatribua a rede correta da máquina virtual à máquina virtual.


+

NOTE: Um servidor DHCP que atribui endereços IP com um MTU inferior a 1500 bytes pode impedir a configuração da rede do nó de gerenciamento ou o uso da interface de usuário do nó de gerenciamento.

. Configure a rede do nó de gerenciamento (eth0).
+

NOTE: Se você precisar de uma placa de rede adicional para isolar o tráfego de armazenamento, consulte as instruções sobre como configurar outra placa de rede:link:task_mnode_install_add_storage_NIC.html["Configure um controlador de interface de rede (NIC) de armazenamento."] .





== Etapa 3: Configurar a sincronização de horário

Antes de configurar o nó de gerenciamento, sincronize o horário entre o nó de gerenciamento e o cluster de armazenamento.

.Passos
. Verifique se a hora está sincronizada entre o nó de gerenciamento e o cluster de armazenamento usando o NTP:



NOTE: A partir do Elemento 12.3.1, as subetapas (a) a (e) são executadas automaticamente.  Para o nó de gerenciamento 12.3.1, prossiga para<<substep_f_install_config_time_sync,subetapa (f)>> Para concluir a configuração de sincronização de horário.

. Faça login no nó de gerenciamento usando SSH ou o console fornecido pelo seu hipervisor.
. Pare o NTPD:
+
[listing]
----
sudo service ntpd stop
----
. Edite o arquivo de configuração do NTP `/etc/ntp.conf` :
+
.. Comente as linhas referentes aos servidores padrão.(`server 0.gentoo.pool.ntp.org` ) adicionando um `#` em frente a cada um.
.. Adicione uma nova linha para cada servidor de horário padrão que você deseja adicionar. Os servidores de horário padrão devem ser os mesmos servidores NTP usados no cluster de armazenamento que você usará em um <<set-up-the-management-node,etapa posterior>>.
+
[listing]
----
vi /etc/ntp.conf

#server 0.gentoo.pool.ntp.org
#server 1.gentoo.pool.ntp.org
#server 2.gentoo.pool.ntp.org
#server 3.gentoo.pool.ntp.org
server <insert the hostname or IP address of the default time server>
----
.. Salve o arquivo de configuração quando terminar.


. Forçar uma sincronização NTP com o servidor recém-adicionado.
+
[listing]
----
sudo ntpd -gq
----
. Reinicie o NTPD.
+
[listing]
----
sudo service ntpd start
----
. [[substep_f_install_config_time_sync]]Desative a sincronização de tempo com o host por meio do hipervisor (o exemplo a seguir é do VMware):
+

NOTE: Se você implantar o mNode em um ambiente de hipervisor diferente do VMware, por exemplo, a partir da imagem .iso em um ambiente Openstack, consulte a documentação do hipervisor para obter os comandos equivalentes.

+
.. Desativar a sincronização periódica de horário:
+
[listing]
----
vmware-toolbox-cmd timesync disable
----
.. Exibir e confirmar o status atual do serviço:
+
[listing]
----
vmware-toolbox-cmd timesync status
----
.. No vSphere, verifique se o `Synchronize guest time with host` A caixa está desmarcada nas opções da máquina virtual.
+

NOTE: Não habilite esta opção se fizer alterações futuras na máquina virtual.






NOTE: Não edite o NTP depois de concluir a configuração de sincronização de tempo, pois isso afetará o NTP quando você executar o programa. <<set-up-the-management-node,comando de configuração>> no nó de gerenciamento.



== Etapa 4: Configurar o nó de gerenciamento

Configure o nó de gerenciamento usando o `setup-mnode` comando.

.Passos
. Configure e execute o comando de configuração do nó de gerenciamento:
+

NOTE: Você será solicitado a inserir senhas em um prompt seguro.  Se o seu cluster estiver atrás de um servidor proxy, você deve configurar as definições de proxy para poder aceder a uma rede pública.

+
[listing]
----
sudo /sf/packages/mnode/setup-mnode --mnode_admin_user [username] --storage_mvip [mvip] --storage_username [username] --telemetry_active [true]
----
+
.. Substitua o valor entre colchetes [ ] (incluindo os colchetes) para cada um dos seguintes parâmetros obrigatórios:
+

NOTE: A forma abreviada do nome do comando está entre parênteses ( ) e pode ser substituída pelo nome completo.

+
*** *--mnode_admin_user (-mu) [nome de usuário]*: O nome de usuário para a conta de administrador do nó de gerenciamento.  Este provavelmente é o nome de usuário da conta que você usou para acessar o nó de gerenciamento.
*** *--storage_mvip (-sm) [Endereço MVIP]*: O endereço IP virtual de gerenciamento (MVIP) do cluster de armazenamento que executa o software Element. Configure o nó de gerenciamento com o mesmo cluster de armazenamento que você usou durante <<configure-time-sync,Configuração de servidores NTP>>.
*** *--storage_username (-su) [nome de usuário]*: O nome de usuário do administrador do cluster de armazenamento para o cluster especificado pelo `--storage_mvip` parâmetro.
*** *--telemetry_active (-t) [true]*: Mantém o valor verdadeiro que permite a coleta de dados para análises pelo Active IQ.


.. (Opcional): Adicione parâmetros de endpoint do Active IQ ao comando:
+
*** *--remote_host (-rh) [AIQ_endpoint]*: O endpoint para onde os dados de telemetria do Active IQ são enviados para serem processados.  Caso o parâmetro não seja incluído, o endpoint padrão será utilizado.


.. (Recomendado): Adicione os seguintes parâmetros de volume persistente.  Não modifique nem exclua a conta e os volumes criados para a funcionalidade de volumes persistentes, caso contrário, haverá perda da capacidade de gerenciamento.
+
*** *--use_persistent_volumes (-pv) [true/false, padrão: false]*: Ativa ou desativa volumes persistentes.  Insira o valor "true" para ativar a funcionalidade de volumes persistentes.
*** *--persistent_volumes_account (-pva) [nome_da_conta]*: Se `--use_persistent_volumes` Se estiver definido como verdadeiro, use este parâmetro e insira o nome da conta de armazenamento que será usada para volumes persistentes.
+

NOTE: Utilize um nome de conta exclusivo para volumes persistentes, que seja diferente de qualquer nome de conta existente no cluster.  É extremamente importante manter a conta de volumes persistentes separada do restante do seu ambiente.

*** *--persistent_volumes_mvip (-pvm) [mvip]*: Insira o endereço IP virtual de gerenciamento (MVIP) do cluster de armazenamento que executa o software Element e que será usado com volumes persistentes.  Isso só é necessário se vários clusters de armazenamento forem gerenciados pelo nó de gerenciamento.  Caso não haja vários clusters gerenciados, o MVIP padrão do cluster será utilizado.


.. Configurar um servidor proxy:
+
*** *--use_proxy (-up) [true/false, padrão: false]*: Ativa ou desativa o uso do proxy.  Este parâmetro é necessário para configurar um servidor proxy.
*** *--proxy_hostname_or_ip (-pi) [host]*: O nome do host ou IP do proxy.  Isso é necessário se você quiser usar um proxy.  Se você especificar isso, será solicitado a inserir... `--proxy_port` .
*** *--proxy_username (-pu) [nome de usuário]*: O nome de usuário do proxy.  Este parâmetro é opcional.
*** *--proxy_password (-pp) [senha]*: A senha do proxy.  Este parâmetro é opcional.
*** *--proxy_port (-pq) [porta, padrão: 0]*: A porta do proxy.  Se você especificar isso, será solicitado a inserir o nome do host ou o endereço IP do proxy.(`--proxy_hostname_or_ip` ).
*** *--proxy_ssh_port (-ps) [porta, padrão: 443]*: A porta do proxy SSH.  Por padrão, utiliza-se a porta 443.


.. (Opcional) Utilize a ajuda de parâmetros caso necessite de informações adicionais sobre cada parâmetro:
+
*** *--help (-h)*: Retorna informações sobre cada parâmetro.  Os parâmetros são definidos como obrigatórios ou opcionais com base na implantação inicial.  Os requisitos de parâmetros para atualização e reimplementação podem variar.


.. Execute o `setup-mnode` comando.






== Etapa 5: Configurar os ativos do controlador

Localize o ID da instalação e adicione um recurso do controlador vCenter.

.Passos
. Localize o ID da instalação:
+
.. A partir de um navegador, faça login na interface de usuário da API REST do nó de gerenciamento:
.. Acesse o MVIP de armazenamento e faça login. Essa ação fará com que o certificado seja aceito para a próxima etapa.
.. Abra a interface de usuário da API REST do serviço de inventário no nó de gerenciamento:
+
[listing]
----
https://<ManagementNodeIP>/inventory/1/
----
.. Selecione *Autorizar* e complete o seguinte:
+
... Insira o nome de usuário e a senha do cluster.
... Insira o ID do cliente como `mnode-client` .
... Selecione *Autorizar* para iniciar uma sessão.


.. Na interface de usuário da API REST, selecione *GET /installations*.
.. Selecione *Experimentar*.
.. Selecione *Executar*.
.. A partir do corpo da resposta com código 200, copie e salve o `id` para a instalação, para uso em uma etapa posterior.
+
Sua instalação possui uma configuração básica de ativos que foi criada durante a instalação ou atualização.



. Adicione um recurso do controlador vCenter para o NetApp Hybrid Cloud Control aos recursos conhecidos do nó de gerenciamento:
+
.. Acesse a interface da API do serviço mnode no nó de gerenciamento inserindo o endereço IP do nó de gerenciamento seguido por `/mnode` :
+
[listing]
----
https://<ManagementNodeIP>/mnode
----
.. Selecione *Autorizar* ou qualquer ícone de cadeado e complete o seguinte:
+
... Insira o nome de usuário e a senha do cluster.
... Insira o ID do cliente como `mnode-client` .
... Selecione *Autorizar* para iniciar uma sessão.
... Fechar a janela.


.. Selecione *POST /assets/{asset_id}/controllers* para adicionar um sub-ativo de controlador.
+

NOTE: Você deve criar uma nova função NetApp HCC no vCenter para adicionar um subativo de controlador.  Essa nova função do NetApp HCC limitará a visualização dos serviços do nó de gerenciamento a ativos exclusivos da NetApp. Verlink:task_mnode_create_netapp_hcc_role_vcenter.html["Criar uma função NetApp HCC no vCenter"] .

.. Selecione *Experimentar*.
.. Insira o ID do recurso base pai que você copiou para a área de transferência no campo *asset_id*.
.. Insira os valores de carga útil necessários com o tipo `vCenter` e credenciais do vCenter.
.. Selecione *Executar*.






== Encontre mais informações

* link:../concepts/concept_solidfire_concepts_volumes.html#persistent-volumes["Volumes persistentes"]
* link:task_mnode_add_assets.html["Adicione um recurso de controlador ao nó de gerenciamento."]
* link:task_mnode_install_add_storage_NIC.html["Configure uma placa de rede de armazenamento (NIC)"]
* https://docs.netapp.com/us-en/vcp/index.html["Plug-in NetApp Element para vCenter Server"^]
* https://docs.netapp.com/us-en/element-software/index.html["Documentação do SolidFire e do Element Software"]

